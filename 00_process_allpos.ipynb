{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Process Multi-Season Data - All Positions\n",
                "\n",
                "This notebook processes raw FBref data from all positions for the Siamese neural network."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from pathlib import Path\n",
                "\n",
                "# Paths\n",
                "DATA_DIR = Path(\"data\")\n",
                "RAW_DIR = DATA_DIR / \"multiseason_data\"\n",
                "\n",
                "print(f\"Raw data directory: {RAW_DIR}\")\n",
                "print(f\"Files: {list(RAW_DIR.glob('merged_*.csv'))}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load All Stat Tables"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load all merged stat tables\n",
                "standard = pd.read_csv(RAW_DIR / \"merged_standard.csv\")\n",
                "passing = pd.read_csv(RAW_DIR / \"merged_passing.csv\")\n",
                "defense = pd.read_csv(RAW_DIR / \"merged_defense.csv\")\n",
                "possession = pd.read_csv(RAW_DIR / \"merged_possession.csv\")\n",
                "shooting = pd.read_csv(RAW_DIR / \"merged_shooting.csv\")\n",
                "misc = pd.read_csv(RAW_DIR / \"merged_misc.csv\")\n",
                "\n",
                "print(f\"Standard: {standard.shape}\")\n",
                "print(f\"Passing: {passing.shape}\")\n",
                "print(f\"Defense: {defense.shape}\")\n",
                "print(f\"Possession: {possession.shape}\")\n",
                "print(f\"Shooting: {shooting.shape}\")\n",
                "print(f\"Misc: {misc.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check position distribution\n",
                "print(\"Position Distribution:\")\n",
                "print(standard['pos'].value_counts())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Check for Duplicates in Raw Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check for duplicates BEFORE merging\n",
                "print(\"=\" * 60)\n",
                "print(\"DUPLICATE CHECK - Raw Data\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "# Check exact duplicates\n",
                "exact_dups = standard.duplicated().sum()\n",
                "print(f\"\\nExact duplicate rows: {exact_dups}\")\n",
                "\n",
                "# Check duplicates by key columns\n",
                "key_cols = ['player', 'team', 'season', 'league']\n",
                "key_dups = standard.duplicated(subset=key_cols).sum()\n",
                "print(f\"Duplicate by [player, team, season, league]: {key_dups}\")\n",
                "\n",
                "# Check same player appearing multiple times in same season (different teams = transfer)\n",
                "player_season_dups = standard.groupby(['player', 'season']).size()\n",
                "multi_team = player_season_dups[player_season_dups > 1]\n",
                "print(f\"\\nPlayers at multiple teams in same season: {len(multi_team)}\")\n",
                "if len(multi_team) > 0:\n",
                "    print(\"Examples:\")\n",
                "    for (player, season), count in multi_team.head(5).items():\n",
                "        teams = standard[(standard['player'] == player) & (standard['season'] == season)]['team'].tolist()\n",
                "        print(f\"  {player} ({season}): {teams}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Remove exact duplicates from all tables\n",
                "print(\"\\nRemoving exact duplicates...\")\n",
                "before = len(standard)\n",
                "standard = standard.drop_duplicates()\n",
                "print(f\"Standard: {before} -> {len(standard)}\")\n",
                "\n",
                "before = len(passing)\n",
                "passing = passing.drop_duplicates()\n",
                "print(f\"Passing: {before} -> {len(passing)}\")\n",
                "\n",
                "before = len(defense)\n",
                "defense = defense.drop_duplicates()\n",
                "print(f\"Defense: {before} -> {len(defense)}\")\n",
                "\n",
                "before = len(possession)\n",
                "possession = possession.drop_duplicates()\n",
                "print(f\"Possession: {before} -> {len(possession)}\")\n",
                "\n",
                "before = len(shooting)\n",
                "shooting = shooting.drop_duplicates()\n",
                "print(f\"Shooting: {before} -> {len(shooting)}\")\n",
                "\n",
                "before = len(misc)\n",
                "misc = misc.drop_duplicates()\n",
                "print(f\"Misc: {before} -> {len(misc)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Merge All Tables"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Key columns for merging\n",
                "KEY_COLS = ['player', 'team', 'season', 'league']\n",
                "\n",
                "# Start with standard stats\n",
                "df = standard.copy()\n",
                "print(f\"Starting shape: {df.shape}\")\n",
                "\n",
                "# Merge other tables\n",
                "tables = [\n",
                "    ('passing', passing),\n",
                "    ('defense', defense),\n",
                "    ('possession', possession),\n",
                "    ('shooting', shooting),\n",
                "    ('misc', misc)\n",
                "]\n",
                "\n",
                "for name, table in tables:\n",
                "    # Get columns to add (exclude duplicates except keys)\n",
                "    existing_cols = set(df.columns)\n",
                "    new_cols = [c for c in table.columns if c not in existing_cols or c in KEY_COLS]\n",
                "    \n",
                "    # Merge\n",
                "    df = df.merge(\n",
                "        table[new_cols],\n",
                "        on=KEY_COLS,\n",
                "        how='left',\n",
                "        suffixes=('', f'_{name}')\n",
                "    )\n",
                "    print(f\"After {name}: {df.shape}\")\n",
                "\n",
                "print(f\"\\nFinal merged shape: {df.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Clean Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Rename columns for clarity\n",
                "df = df.rename(columns={\n",
                "    'player': 'Player',\n",
                "    'team': 'Squad',\n",
                "    'pos': 'Pos',\n",
                "    'age': 'Age',\n",
                "    'nation': 'Nation',\n",
                "    'league': 'League',\n",
                "    'season': 'Season'\n",
                "})\n",
                "\n",
                "print(f\"Columns: {list(df.columns[:20])}...\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clean age column (extract numeric age)\n",
                "def clean_age(age_str):\n",
                "    if pd.isna(age_str):\n",
                "        return np.nan\n",
                "    try:\n",
                "        # Handle \"25-123\" format (age-days)\n",
                "        if isinstance(age_str, str) and '-' in age_str:\n",
                "            return int(age_str.split('-')[0])\n",
                "        return int(float(age_str))\n",
                "    except:\n",
                "        return np.nan\n",
                "\n",
                "df['Age'] = df['Age'].apply(clean_age)\n",
                "print(f\"Age range: {df['Age'].min()} - {df['Age'].max()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Filter: minimum playing time (at least 2 x 90 minutes)\n",
                "MIN_90S = 2.0\n",
                "\n",
                "# Find 90s column\n",
                "nineties_col = None\n",
                "for col in df.columns:\n",
                "    if '90s' in str(col).lower():\n",
                "        nineties_col = col\n",
                "        break\n",
                "\n",
                "if nineties_col:\n",
                "    before = len(df)\n",
                "    df = df[df[nineties_col] >= MIN_90S]\n",
                "    print(f\"Filtered by {nineties_col} >= {MIN_90S}: {before} -> {len(df)} rows\")\n",
                "else:\n",
                "    print(\"Warning: 90s column not found\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Remove goalkeepers (they have very different stats)\n",
                "before = len(df)\n",
                "df = df[~df['Pos'].str.contains('GK', na=False)]\n",
                "print(f\"Removed goalkeepers: {before} -> {len(df)} rows\")\n",
                "\n",
                "print(f\"\\nPosition distribution after filtering:\")\n",
                "print(df['Pos'].value_counts())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Handle Duplicates & Aggregate"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check duplicates after cleaning\n",
                "print(\"=\" * 60)\n",
                "print(\"DUPLICATE CHECK - After Cleaning\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "# Total rows vs unique players\n",
                "print(f\"\\nTotal rows: {len(df)}\")\n",
                "print(f\"Unique players: {df['Player'].nunique()}\")\n",
                "\n",
                "# Players appearing multiple times\n",
                "player_counts = df['Player'].value_counts()\n",
                "multi_appearance = player_counts[player_counts > 1]\n",
                "print(f\"Players with multiple rows: {len(multi_appearance)}\")\n",
                "\n",
                "# Show examples\n",
                "if len(multi_appearance) > 0:\n",
                "    print(f\"\\nExamples of players with multiple entries:\")\n",
                "    for player in multi_appearance.head(5).index:\n",
                "        player_rows = df[df['Player'] == player][['Player', 'Squad', 'Season', 'Pos']]\n",
                "        print(f\"\\n  {player}:\")\n",
                "        for _, row in player_rows.iterrows():\n",
                "            print(f\"    - {row['Season']} | {row['Squad']} | {row['Pos']}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Identify numeric columns for aggregation\n",
                "id_cols = ['Player', 'Squad', 'Pos', 'Nation', 'League', 'Age', 'born', 'Season']\n",
                "numeric_cols = [c for c in df.columns if c not in id_cols \n",
                "                and df[c].dtype in ['int64', 'float64']]\n",
                "\n",
                "print(f\"Numeric columns to aggregate: {len(numeric_cols)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Aggregate: For players with multiple entries, take WEIGHTED AVERAGE by 90s played\n",
                "# This gives more weight to seasons/stints where they played more\n",
                "\n",
                "def weighted_aggregate(group):\n",
                "    \"\"\"Aggregate player stats weighted by playing time.\"\"\"\n",
                "    result = {}\n",
                "    \n",
                "    # For ID columns, take the most recent (last) entry\n",
                "    result['Squad'] = group['Squad'].iloc[-1]\n",
                "    result['Pos'] = group['Pos'].iloc[-1]\n",
                "    result['Nation'] = group['Nation'].iloc[-1] if 'Nation' in group.columns else None\n",
                "    result['League'] = group['League'].iloc[-1]\n",
                "    result['Age'] = group['Age'].iloc[-1]\n",
                "    \n",
                "    # Get weights (90s played)\n",
                "    weights = group['90s'].values if '90s' in group.columns else np.ones(len(group))\n",
                "    weights = np.maximum(weights, 0.1)  # Avoid division by zero\n",
                "    \n",
                "    # Weighted average for numeric columns\n",
                "    for col in numeric_cols:\n",
                "        if col in group.columns:\n",
                "            values = group[col].values\n",
                "            # Handle NaN: use only non-NaN values\n",
                "            mask = ~np.isnan(values)\n",
                "            if mask.any():\n",
                "                result[col] = np.average(values[mask], weights=weights[mask])\n",
                "            else:\n",
                "                result[col] = np.nan\n",
                "    \n",
                "    return pd.Series(result)\n",
                "\n",
                "print(\"Aggregating players (weighted by playing time)...\")\n",
                "df_agg = df.groupby('Player').apply(weighted_aggregate).reset_index()\n",
                "\n",
                "print(f\"\\nAfter aggregation: {df_agg.shape}\")\n",
                "print(f\"Unique players: {df_agg['Player'].nunique()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# FINAL DUPLICATE CHECK\n",
                "print(\"=\" * 60)\n",
                "print(\"FINAL DUPLICATE CHECK\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "final_dups = df_agg['Player'].duplicated().sum()\n",
                "print(f\"\\nDuplicate players remaining: {final_dups}\")\n",
                "\n",
                "if final_dups > 0:\n",
                "    print(\"WARNING: Still have duplicates!\")\n",
                "    print(df_agg[df_agg['Player'].duplicated(keep=False)][['Player', 'Squad', 'Pos']])\n",
                "else:\n",
                "    print(\"âœ“ All players are unique!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Drop rows with too many missing values\n",
                "threshold = 0.5  # At least 50% of numeric columns must have values\n",
                "min_non_null = int(len(numeric_cols) * threshold)\n",
                "\n",
                "before = len(df_agg)\n",
                "df_agg = df_agg.dropna(subset=numeric_cols, thresh=min_non_null)\n",
                "print(f\"Dropped rows with >50% missing: {before} -> {len(df_agg)} players\")\n",
                "\n",
                "# Fill remaining NaN with 0\n",
                "df_agg[numeric_cols] = df_agg[numeric_cols].fillna(0)\n",
                "\n",
                "print(f\"\\nFinal dataset: {df_agg.shape}\")\n",
                "print(f\"\\nPosition breakdown:\")\n",
                "print(df_agg['Pos'].value_counts())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Create Feature List"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Identify feature columns\n",
                "exclude_cols = ['Player', 'Squad', 'Pos', 'Nation', 'League', 'Age', 'born', 'Season']\n",
                "feature_cols = [c for c in df_agg.columns if c not in exclude_cols \n",
                "                and df_agg[c].dtype in ['int64', 'float64']]\n",
                "\n",
                "print(f\"Feature columns: {len(feature_cols)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Feature name mappings\n",
                "feature_mapping = {\n",
                "    'Playing Time': 'Matches Played',\n",
                "    'Playing Time.1': 'Starts',\n",
                "    'Playing Time.2': 'Minutes',\n",
                "    'Playing Time.3': 'Minutes per Match',\n",
                "    'Performance': 'Goals',\n",
                "    'Performance.1': 'Assists',\n",
                "    'Performance.2': 'Goals + Assists',\n",
                "    'Performance.3': 'Non-Penalty Goals',\n",
                "    'Performance.4': 'Penalty Goals',\n",
                "    'Performance.5': 'Penalty Attempts',\n",
                "    'Performance.6': 'Yellow Cards',\n",
                "    'Performance.7': 'Red Cards',\n",
                "    'Expected': 'xG (Expected Goals)',\n",
                "    'Expected.1': 'npxG (Non-Penalty xG)',\n",
                "    'Expected.2': 'xAG (Expected Assists)',\n",
                "    'Expected.3': 'npxG + xAG',\n",
                "    'Expected.4': 'npxG per Shot',\n",
                "    'Progression': 'Progressive Carries',\n",
                "    'Progression.1': 'Progressive Passes',\n",
                "    'Progression.2': 'Progressive Passes Received',\n",
                "    'Per 90 Minutes': 'Goals per 90',\n",
                "    'Per 90 Minutes.1': 'Assists per 90',\n",
                "    'Per 90 Minutes.2': 'G+A per 90',\n",
                "    'Per 90 Minutes.3': 'Non-Penalty Goals per 90',\n",
                "    'Per 90 Minutes.4': 'G+A-PK per 90',\n",
                "    'Per 90 Minutes.5': 'xG per 90',\n",
                "    'Per 90 Minutes.6': 'xAG per 90',\n",
                "    'Per 90 Minutes.7': 'xG+xAG per 90',\n",
                "    'Per 90 Minutes.8': 'npxG per 90',\n",
                "    'Per 90 Minutes.9': 'npxG+xAG per 90',\n",
                "    '90s': '90-minute periods played',\n",
                "    'Standard': 'Shots Total',\n",
                "    'Standard.1': 'Shots on Target',\n",
                "    'Standard.2': 'SoT%',\n",
                "    'Standard.3': 'Shots per 90',\n",
                "    'Standard.4': 'SoT per 90',\n",
                "    'Standard.5': 'Goals per Shot',\n",
                "    'Standard.6': 'Goals per SoT',\n",
                "    'Standard.7': 'Avg Shot Distance',\n",
                "    'Standard.8': 'Free Kick Shots',\n",
                "    'Standard.9': 'PK Made',\n",
                "    'Standard.10': 'PK Attempted',\n",
                "    'Standard.11': 'xG per Shot',\n",
                "    'Total': 'Passes Completed',\n",
                "    'Total.1': 'Passes Attempted',\n",
                "    'Total.2': 'Pass %',\n",
                "    'Total.3': 'Total Pass Distance',\n",
                "    'Total.4': 'Progressive Pass Distance',\n",
                "    'Short': 'Short Passes Completed',\n",
                "    'Short.1': 'Short Passes Attempted',\n",
                "    'Short.2': 'Short Pass %',\n",
                "    'Medium': 'Medium Passes Completed',\n",
                "    'Medium.1': 'Medium Passes Attempted',\n",
                "    'Medium.2': 'Medium Pass %',\n",
                "    'Long': 'Long Passes Completed',\n",
                "    'Long.1': 'Long Passes Attempted',\n",
                "    'Long.2': 'Long Pass %',\n",
                "    'KP': 'Key Passes',\n",
                "    '1/3': 'Passes into Final Third',\n",
                "    'PPA': 'Passes into Penalty Area',\n",
                "    'CrsPA': 'Crosses into Penalty Area',\n",
                "    'PrgP': 'Progressive Passes',\n",
                "    'Touches': 'Total Touches',\n",
                "    'Touches.1': 'Def Penalty Area Touches',\n",
                "    'Touches.2': 'Def Third Touches',\n",
                "    'Touches.3': 'Mid Third Touches',\n",
                "    'Touches.4': 'Att Third Touches',\n",
                "    'Touches.5': 'Att Penalty Area Touches',\n",
                "    'Touches.6': 'Live Ball Touches',\n",
                "    'Take-Ons': 'Dribbles Attempted',\n",
                "    'Take-Ons.1': 'Successful Dribbles',\n",
                "    'Take-Ons.2': 'Dribble Success %',\n",
                "    'Take-Ons.3': 'Times Tackled',\n",
                "    'Take-Ons.4': 'Tackled %',\n",
                "    'Carries': 'Total Carries',\n",
                "    'Carries.1': 'Carry Distance',\n",
                "    'Carries.2': 'Progressive Carry Distance',\n",
                "    'Carries.3': 'Progressive Carries',\n",
                "    'Carries.4': 'Carries into Final Third',\n",
                "    'Carries.5': 'Carries into Penalty Area',\n",
                "    'Carries.6': 'Miscontrols',\n",
                "    'Carries.7': 'Dispossessed',\n",
                "    'Receiving': 'Passes Received',\n",
                "    'Receiving.1': 'Progressive Passes Received',\n",
                "    'Tackles': 'Tackles',\n",
                "    'Tackles.1': 'Tackles Won',\n",
                "    'Tackles.2': 'Def Third Tackles',\n",
                "    'Tackles.3': 'Mid Third Tackles',\n",
                "    'Tackles.4': 'Att Third Tackles',\n",
                "    'Challenges': 'Dribblers Tackled',\n",
                "    'Challenges.1': 'Dribbles Challenged',\n",
                "    'Challenges.2': 'Challenge %',\n",
                "    'Challenges.3': 'Dribblers Past',\n",
                "    'Blocks': 'Total Blocks',\n",
                "    'Blocks.1': 'Shots Blocked',\n",
                "    'Blocks.2': 'Passes Blocked',\n",
                "    'Int': 'Interceptions',\n",
                "    'Tkl+Int': 'Tackles + Interceptions',\n",
                "    'Clr': 'Clearances',\n",
                "    'Err': 'Errors Leading to Shot',\n",
                "    'Aerial Duels': 'Aerials Won',\n",
                "    'Aerial Duels.1': 'Aerials Lost',\n",
                "    'Aerial Duels.2': 'Aerial Win %'\n",
                "}\n",
                "\n",
                "# Write feature file\n",
                "with open(DATA_DIR / 'clustering_features_allpos.txt', 'w', encoding='utf-8') as f:\n",
                "    f.write('# All Positions Clustering Features\\n')\n",
                "    f.write('# ==================================\\n\\n')\n",
                "    for col in feature_cols:\n",
                "        readable = feature_mapping.get(col, col)\n",
                "        f.write(f\"{col}          # {readable}\\n\")\n",
                "\n",
                "print(f\"Saved feature list to {DATA_DIR / 'clustering_features_allpos.txt'}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Save Processed Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save the processed data\n",
                "output_file = DATA_DIR / 'players_allpos_multiseason.csv'\n",
                "df_agg.to_csv(output_file, index=False)\n",
                "\n",
                "print(f\"\\n{'='*60}\")\n",
                "print(f\"SAVED: {output_file}\")\n",
                "print(f\"{'='*60}\")\n",
                "print(f\"Total unique players: {len(df_agg)}\")\n",
                "print(f\"Total features: {len(feature_cols)}\")\n",
                "print(f\"\\nPosition breakdown:\")\n",
                "for pos, count in df_agg['Pos'].value_counts().items():\n",
                "    print(f\"  {pos:10s}: {count:4d} players\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Final sanity check\n",
                "print(\"\\nSample players:\")\n",
                "sample = df_agg.sample(10)[['Player', 'Squad', 'Pos', 'Age']]\n",
                "display(sample)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}